# Blazing Arrogance, In-Breeding, Exceptionalism, and, Fads

Functional programming is a fad.

Programming, as we practice it today, is based on arrogance, in-breeding and exceptionalism.

Programmers think that programming is special and unique.

For example, programmers think that concurrency and scalability are difficult problems.  Yet, humanity has already solved these problems. We see the solutions every day.

In non-programmer speak - human-speak - concurrency is called "individualism" and "free will".

In human-speak, scalability is called "business organization".

Feynman stopped using clay-tablet mathematical notation long enough to invent Feynman diagrams.

Nobel laureate Prigogene realized that one of the tenets of functional thinking - reversibility - is just plain wrong and wrote "Order Out Of Chaos".

# Science
We, currently, try to apply Science to everything.

But, Science, by itself, is provably insufficient.

Science is thought to explain Physics.

Yet, Science falls woefully short of explaining Physics and Reality.

For example, 85% of the Universe is Dark Matter - not explained by Science

*Can* you explain Dark Matter using Science-as-mathematics.  Probably.  Is this a good idea?

# Clockwork Is Brittle, Not Robust
Designing something as clockwork

Gears, coupling, move here, effect over there

Micro-management.

If a gear tooth breaks, the whole device ceases to function.  

The device is brittle.

Software, today, is like that.  

Brittle.  

Not robust.

It is *possible* to forcibly design robustness into a clockwork product, but this not encouraged nor helped by the clockwork notation.

- 
# Protocols
Protocols are developed to allow interaction between individuals.

## Synchronizing Protocols
For example, some of the concurrency protocols we use every day might include: 
- "We won't start the meeting without you", or
- "He's late, we'll just go ahead without him".

## Morality
Morality is a protocol that fights exceptionalism.

Morality tries to enforce the notion that everyone is equal to you and that no-one is inferior to you.

When you believe that someone is stupider than you or inferior to you, 
- it becomes OK to treat them like cattle 
- it becomes OK to rip them off
- it becomes OK to treat them like machines that will do your bidding
- it becomes OK to imagine that they are dispensible.

In software, the morality protocol is couched as *priorities*.

## Business
Business organization is a protocol for scalability.

Managers make requests downwards and wait for summaries bubbling back upwards.

Managers communicate only with the group that reports to them and to their own manager.

Managers don't micro-manage the levels below them and are not micro-managed by levels above them.

When this protocol is followed, the business is scalable.

The business is not scalable if the tree structured ORG is side-stepped via micro-management and going over the boss's head, or, if any particular manager/group makes itself "indispensible".


"going over the boss's head"
"micro-management"
"job security"

project management vs. engineering

In software, 

Trees are 2D by necessity of using clay-tablet notations.  Humans don't think in terms of tree drawings unless forced to use 2D clay-tablet notations.

A medium that allows "diving down" into nodes could allow a "more natural" representation of structures as nested envelopes which are relative to one another (hierarchy).

A one-size-fits-all mentality arises from the use of 2D clay-tablet notation.  A medium that allows 3D "views" on the same dataset (data, program, etc.) might allow multiple notations to be used in a single solution.
## Concurrency and Independence
### Handshakes
### Interaction With Other People
#### Synchronous - Phones, Facetime, Chats
#### Asynchronous - Email, Phone Messages, Messaging

# Micro-Management
# Scalability
- "not going over the boss's head"
- not micro-managing
- compartmentalization, need to know, 
- summaries upwards
	- filter out details
- commands / requests downwards
	- not micro-management, 
		- "what" not "how"

# 4D Thinking For Our 3D Brains
Computers are like a new medium, overtaking paper and clay tablets.

On paper and clay tablets, we are forced to reduce everything to 2D.  

Functional Thinking simply ignores reality and discards one of the dimensions (time).  The 3rd dimension is "modelled", making it seem unduly complicated.  Modeling is OK, but building the dimension into the notation would encourage simplicity.

Now, we can use computers to envision problems in 4D - x, y, z, and t.  We are no longer relagated to using sharp, graphite sticks and paper.

## Tensors
We invented Tensors as a notation to think about - model - vectors in 3 dimensions.

This notation leads to laborious effort on our part.

Now, we can push manipulation of Tensors (and more) off onto computers.  Computers don't mind performing repetitive notation manipulations.  Humans mind doing this and usually make mistakes (probably out of boredom).

## Mathematical Notation and Microsoft Word

A tenet of mathematics - mathematical notation - is that "side effects" are forbidden.

When you can guarantee no side-effects you can perform simple textual substitutions on the notations.

In programming, we call this "referential transparency".

In Microsoft Word, we call this "search and replace".

## Notation Worship

Mathematics is more than just a notation.

Mathematics breaks down - broadly - into 2 categories:
1. notation, expression
2. deep thought.

How we express (1) - the notation - affects what we can think about in (2) - analysis.

If all you have is a clay tablet, then everything looks like a function.

The "hard problems" in computing, e.g. concurrency and scalability, are only "hard" because we try to express and think about these problems using clay-tablet notation.

Feynman invented Feynman diagrams to allow himself to think deeply about one aspect ("one view") of Physics.  Clay-tablet, functional notation failed him, diagrams freed his mind.

# Everyone Is Stupider Than You
Exceptionalism is the idea that you are somehow better than the other person.

Exceptionalism breeds contempt for other points of view, also known as "reuse".

We see exceptionalism in Computer Science

## GUIs Are Worse Now Than They Were In The 1980s
GUIs are worse in 202x than they were in 1980.  

We are exposed to uncaught exceptions instead of useful error messages.

We see editors that bounce text and redraw it at their own will, instead of the will of the user.

GUI design of the 1980s is ignored because of the belief that those people are old and, therefore, stupider than people in 202x.  And, because Functional Programming is The True Answer to Everything, including GUI design.  

If you don't believe in the Functional Programming fad, you must be stupid. 

# Debuggers Are Worse

The Functional Programming Fad has ignored debuggers and/or made them worse.

Debuggers are vital to Iterative Design.

Debuggers are not needed only for Waterfall Design.

If you don't use a debugger, you might ask yourself why, and, what are you really doing?

# Bloatware
# Waterfall Design

# Science Is About Failing Fast
The founding principle of Science is:
1. Create a Theory
2. Disprove the Theory.

We've spent 70+ years trying to prove that Functional Programming is The Answer to Everything.  Is that Science?

# One Size Fits All - Not

We talk about "divide and conquer", but, don't actually employ this principle to any substantial depth.

We've been using one - and only one - idea called "functions" for decades in Computer "Science".

If we truly believed in "divide and conquer" we might ask ourselves if functions are good for Everything, or, should we try something else?

What is currently considered to be difficult?  Let's pick on concurrency. Concurrency is considered to be difficult and complicated and filled with complicated nuance.  We saw a public failure of an expensive project - the Mars Pathfinder - due to epicycles caused by concurrency "issues" (priority inversion).  Instead of asking ourselves whether we should keep couching concurrency using functions, we lathered yet another epicycle onto the notation ("priority inheritance").

*Should* we continue using the notion of functions to think about concurrency?  Or, should we apply "divide and conquer" and use some other kind of notion?  

Observation: Functions exhibit blocking behaviour.  A caller pauses and waits for an answer from a callee.

Observation: Functions imply LIFO behaviour.  Concurrency might be easier to express using FIFO behaviour.  LIFOs are Stacks.  FIFOs are queues.

Divide and Conquer.  Switch notations (aka "languages") when something seems difficult.

## Programming Languages Are All The Same
As far as LIFO behaviour is concerned, all of today's popular programming languages are the same.  They all use function calls and function returns.  This implies Stacks, LIFO behaviour.

The UNIX language "/bin/sh", though, uses FIFOs when creating pipelines[^1].  FIFO-based pipelines are *very* different from LIFO-based functions, yet, appear to be tantalizingly similar.

[^1]: Then, ruins the concept by relying on clockwork, rendezvous-based scheduling.

# 0D
[[Dependencies]]
??? === biggest problem is dependencies

--- 
notes:

- Programming exceptionalism causes us to ignore previous solutions to problems thinking that the problem we've got is different than the problem it was already solved
- Because asynchronocity in programming is different than asynchronicity in electronics
- EEs are obviously stupider than computer scientists even though everything EEs do involve concurrent asynchronous components.  EEs managed to make things work with such asynchronous elements, several decades ago.  EEs developed CPUs, but, are too stupid to write programs, which is solely the domain of Computer Scientists.